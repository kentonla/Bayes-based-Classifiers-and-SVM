{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dc3RwoSBTLbD"
   },
   "source": [
    "# **HW 3: Bayes-based Classifiers and SVM**\n",
    "**HW Due date is 03/11/2025, 23:59 pm**\n",
    "\n",
    "Objective:\n",
    "* To understand the basics of Naive Bayes, and SVM classifiers.\n",
    "* To practice building these models using sample datasets.\n",
    "* To visualize model performance and apply hyperparameter tuning techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iczz9_bZZ2g3"
   },
   "outputs": [],
   "source": [
    "# Load the Cleveland Heart Disease dataset\n",
    "# Replace 'path_to_your_file.data' with the actual path to your .data file\n",
    "heart_df = pd.read_csv(\"path_to_your_file.data\", header=None, delimiter=',')\n",
    "selected_columns = [0, 1, 2, 3, 4, 13] # for now we only use first 5 attributes and target class. You might want to include other attributes to see how the accuracy of the trained models are changing!\n",
    "heart_df = heart_df.iloc[:, selected_columns]\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'HD']\n",
    "heart_df.columns = column_names\n",
    "heart_df['HD'] = (heart_df['HD'] > 0).astype(int) #This line converts the 'HD' column into a binary attribute, where any value greater\n",
    " # than 0 is considered as presence of heart disease (1), and 0 otherwise.\"\"\"\n",
    "\n",
    "# dataset is from this link: https://archive.ics.uci.edu/dataset/45/heart+disease\n",
    "#sex: sex (1 = male; 0 = female)\n",
    "\"\"\"cp: chest pain type\n",
    "-- Value 1: typical angina\n",
    "-- Value 2: atypical angina\n",
    "-- Value 3: non-anginal pain\n",
    "-- Value 4: asymptomatic\"\"\"\n",
    "#trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "#chol: serum cholestoral in mg/dl\n",
    "\"\"\"HD: diagnosis of heart disease (angiographic disease status)\n",
    "-- Value 0: < 50% diameter narrowing\n",
    "-- Value 1: > 50% diameter narrowing\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "zMDeDxTJuPxQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from pgmpy.models import BayesianNetwork\n",
    "\n",
    "\n",
    "# Splitting features and target\n",
    "X = heart_df.drop(columns=['HD'])\n",
    "y = heart_df['HD']\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "## Your code starts here\n",
    "\n",
    "## Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iI94lvmO24w0"
   },
   "source": [
    "Use Naive Bayes classifier to get a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j4uVLbU8uTyN"
   },
   "outputs": [],
   "source": [
    "# Step 3: Initial Evaluation with Naive Bayes\n",
    "## Your code starts here\n",
    "\n",
    "## Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONxW-iZk3Dbp"
   },
   "source": [
    "**Question:** I got an accuracy of 67.2%. What can you do to improve on that using Naive Bayes Classifier?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ASQAp86zuvEU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate the correlation matrix\n",
    "## Your code starts here\n",
    "\n",
    "## Your code ends here\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# You can also visualize the correlation matrix for better interpretation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_-2W-L2T0-D"
   },
   "source": [
    "Now, Apply SVM models to the same dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_33hIx3YPed2",
    "outputId": "7e647a20-7803-4488-c615-0dfad1fad343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Classifier with Poly Kernel Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65        29\n",
      "           1       0.70      0.22      0.33        32\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.60      0.56      0.49        61\n",
      "weighted avg       0.61      0.54      0.48        61\n",
      "\n",
      "Accuracy: 0.5409836065573771\n",
      "\n",
      "SVM Classifier with Rbf Kernel Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.79      0.59        29\n",
      "           1       0.50      0.19      0.27        32\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.48      0.49      0.43        61\n",
      "weighted avg       0.49      0.48      0.42        61\n",
      "\n",
      "Accuracy: 0.47540983606557374\n",
      "\n",
      "SVM Classifier with Sigmoid Kernel Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.76      0.57        29\n",
      "           1       0.46      0.19      0.27        32\n",
      "\n",
      "    accuracy                           0.46        61\n",
      "   macro avg       0.46      0.47      0.42        61\n",
      "weighted avg       0.46      0.46      0.41        61\n",
      "\n",
      "Accuracy: 0.45901639344262296\n",
      "\n",
      "Best Parameters: {'C': 10, 'gamma': 0.001}\n",
      "Tuned SVM Classifier Metrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50        29\n",
      "           1       0.56      0.59      0.58        32\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.54      0.54      0.54        61\n",
      "weighted avg       0.54      0.54      0.54        61\n",
      "\n",
      "Accuracy: 0.5409836065573771\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Comparison with SVM Classifiers: apply linear and a non-linear SVM classifiers\n",
    "## Your code starts here\n",
    "\n",
    "## Your code ends here\n",
    "print(\"Linear SVM Accuracy:\", linear_svm_accuracy)\n",
    "\n",
    "## Your code starts here\n",
    "\n",
    "## Your code ends here\n",
    "print(\"Non-linear SVM Accuracy:\", nonlinear_svm_accuracy)\n",
    "\n",
    "# Task 3: Exploring Different Kernels\n",
    "kernels = ['poly', 'rbf', 'sigmoid']\n",
    "for kernel in kernels:\n",
    "## Your code starts here\n",
    "\n",
    "## Your code ends here\n",
    "\n",
    "# Task 4: Hyperparameter Tuning : Use GridSearchCV to find the best hyperparameters and print them out\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001]}\n",
    "svm_classifier = SVC(kernel='rbf')\n",
    "grid_search = ## Your code starts here\n",
    "\n",
    "## Your code ends here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT-jW0BzUQ7e"
   },
   "source": [
    "# Submission Guidelines:\n",
    "\n",
    "* Implement the above steps in a Jupyter Notebook file.\n",
    "* Save your ipython code and name it as: lastname_firstname_HW3.ipynb (.ipynb extension)\n",
    "* Include comments and explanations to describe your approach and the rationale behind each step.\n",
    "* Submit on Canvas."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
